GAN architecture options:
Vanilla? One generator one discriminator.
conditional W-GAN.
Generative Multi-Adversarial Networks? multiple discriminator receiving varying real images to compare with the fake.
BEGAN? encoder decoder architecture
BiGAN? - to create good embeddings representation.

TODOS:
1. create architectures for generator based on dataset type.
2. implement Dense layer for each feature at generator. For each dataset create the appropriate implmetation.
3. Gumbel softmax implementation as final layer for generator (categorical features only).
https://arxiv.org/pdf/1611.01144.pdf
https://www.youtube.com/watch?v=JFgXEbgcT7g&t=38s
https://github.com/gugarosa/nalp/blob/master/nalp/models/layers/gumbel_softmax.py - implementation as a layer
https://github.com/vithursant/VAE-Gumbel-Softmax/blob/master/notebooks/concrete_distribution.ipynb - usage withing regular softmax see cell 14

4. min-max scaler for [-1, 1] - TO DISCUSS AND DECIDE FIRST


resources:
https://www.tensorflow.org/tutorials/generative/dcgan
https://towardsdatascience.com/review-of-gans-for-tabular-data-a30a2199342
https://towardsdatascience.com/generating-synthetic-tabular-data-503fe823f377

Papers:
https://arxiv.org/abs/1907.00503 (2019)
https://www.sciencedirect.com/science/article/pii/S0957417421000233 (2021)
https://arxiv.org/abs/2102.08369


Evaluation:
1. simple model fitting on real data and test on generated. - Yishaia DONE
2. Table evaluator. - Yishaia
3. statistic significance and visualization of distribution.
4. euclidean distance from either - closest sample, or an average of all from same class (TBD).
5. PCA/tSNE - observe/compare the clustering of lower dimensionality of both generated and real data.
6. KL-divergence.

